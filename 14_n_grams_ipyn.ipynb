{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "14.n_grams.ipyn",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q2CKdGITXj5-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "\n",
        "plt.style.use(style='seaborn')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('all-data.csv',encoding = \"ISO-8859-1\", header=None, names = ['Sentiment', 'News Headline'])\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "JeG3PJ8kXt5g",
        "outputId": "8753ad1b-23a9-4274-c9aa-82736e4a34f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3fb5a6f45af8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all-data.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ISO-8859-1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'News Headline'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'all-data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "vyvXAqi1X8C6",
        "outputId": "3c3d8686-726e-4959-830b-8d14422ec6aa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-a74c58233b9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "afI3-ja_YD7S",
        "outputId": "c569de81-f3be-45f7-912e-5085ac5a613b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-39de6da29611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentiment'].value_counts()"
      ],
      "metadata": {
        "id": "G0t2mK1RYFki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=df['Sentiment'].values\n",
        "y.shape"
      ],
      "metadata": {
        "id": "tA0LXKVjYHSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=df['News Headline'].values\n",
        "x.shape"
      ],
      "metadata": {
        "id": "5iCWgRgHYJH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "YjsTrLn4YK-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,x_test,y_train,y_test)=train_test_split(x,y,test_size=0.4)"
      ],
      "metadata": {
        "id": "OEsL9ZGLYMp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "KjNcrhETYOL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "rNQ8r78EYQJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "id": "zxMJhbAAYRke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "id": "Fq0oBD-HYTBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "id": "eJuOzEl-YUJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=pd.DataFrame(x_train)\n",
        "df1=df1.rename(columns={0:'news'})\n",
        "\n",
        "df2=pd.DataFrame(y_train)\n",
        "df2=df2.rename(columns={0:'sentiment'})\n",
        "df_train=pd.concat([df1,df2],axis=1)\n",
        "\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "CUDRegMKYVly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()"
      ],
      "metadata": {
        "id": "HiFTd4LgYXEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3=pd.DataFrame(x_test)\n",
        "df3=df3.rename(columns={0:'news'})\n",
        "\n",
        "df4=pd.DataFrame(y_test)\n",
        "df4=df2.rename(columns={0:'sentiment'})\n",
        "df_test=pd.concat([df3,df4],axis=1)\n",
        "\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "O41t08WXYYWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.info()"
      ],
      "metadata": {
        "id": "6lZmK00mYZo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing punctuations\n",
        "#library that contains punctuation\n",
        "import string\n",
        "string.punctuation"
      ],
      "metadata": {
        "id": "XuxnkmJWYbUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the function to remove punctuation\n",
        "def remove_punctuation(text):\n",
        "  if(type(text)==float):\n",
        "    return text\n",
        "  ans=\"\"  \n",
        "  for i in text:     \n",
        "    if i not in string.punctuation:\n",
        "      ans+=i    \n",
        "  return ans\n",
        "\n",
        "#storing the puntuation free text in a new column called clean_msg\n",
        "df_train['news']= df_train['news'].apply(lambda x:remove_punctuation(x))\n",
        "df_test['news']= df_test['news'].apply(lambda x:remove_punctuation(x))"
      ],
      "metadata": {
        "id": "2pzY2IYiYdNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()\n",
        "#punctuations are removed from news column in train dataset"
      ],
      "metadata": {
        "id": "GqqOwUFrYei6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "WCl6zHIxYf6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "4Q_aP7JlYhGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#method to generate n-grams:\n",
        "#params:\n",
        "#text-the text for which we have to generate n-grams\n",
        "#ngram-number of grams to be generated from the text(1,2,3,4 etc., default value=1)\n",
        "\n",
        "\n",
        "def generate_N_grams(text,ngram=1):\n",
        "  words=[word for word in text.split(\" \") if word not in set(stopwords.words('english'))]  \n",
        "  print(\"Sentence after removing stopwords:\",words)\n",
        "  temp=zip(*[words[i:] for i in range(0,ngram)])\n",
        "  ans=[' '.join(ngram) for ngram in temp]\n",
        "  return ans"
      ],
      "metadata": {
        "id": "78Q6eqr9YjAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample!\n",
        "generate_N_grams(\"The sun rises in the east\",3)"
      ],
      "metadata": {
        "id": "Ja5koOSYYkNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "24RgIMFrYlZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positiveValues=defaultdict(int)\n",
        "negativeValues=defaultdict(int)\n",
        "neutralValues=defaultdict(int)\n",
        "#get the count of every word in both the columns of df_train and df_test dataframes"
      ],
      "metadata": {
        "id": "k_TgoDYUYmv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the count of every word in both the columns of df_train and df_test dataframes where sentiment=\"positive\"\n",
        "for text in df_train[df_train.sentiment==\"positive\"].news:\n",
        "  for word in generate_N_grams(text):\n",
        "    positiveValues[word]+=1\n",
        "\n",
        "#get the count of every word in both the columns of df_train and df_test dataframes where sentiment=\"negative\"\n",
        "for text in df_train[df_train.sentiment==\"negative\"].news:\n",
        "  for word in generate_N_grams(text):\n",
        "    negativeValues[word]+=1\n",
        "\n",
        "#get the count of every word in both the columns of df_train and df_test dataframes where sentiment=\"neutral\"\n",
        "for text in df_train[df_train.sentiment==\"neutral\"].news:\n",
        "  for word in generate_N_grams(text):\n",
        "    neutralValues[word]+=1"
      ],
      "metadata": {
        "id": "RbohzgZGYoUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positiveValues\n",
        "#output is a dictionary-list of words in news column and the count of each of these words in train dataset where sentiment=positive"
      ],
      "metadata": {
        "id": "Pt_Gj_KWZcHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positiveValues.items()\n",
        "#o/p is a dictionary with the word in news column as key and its count within the train dataset as its corresponding value"
      ],
      "metadata": {
        "id": "1y7fuYlkZgBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#focus on more frequently occuring words for every sentiment=>\n",
        "#sort in DO wrt 2nd column in each of positiveValues,negativeValues and neutralValues\n",
        "\n",
        "df_positive=pd.DataFrame(sorted(positiveValues.items(),key=lambda x:x[1],reverse=True))\n",
        "df_negative=pd.DataFrame(sorted(negativeValues.items(),key=lambda x:x[1],reverse=True))\n",
        "df_neutral=pd.DataFrame(sorted(neutralValues.items(),key=lambda x:x[1],reverse=True))"
      ],
      "metadata": {
        "id": "4QKzNiX2Zi6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd1=df_positive[0][:10]\n",
        "pd2=df_positive[1][:10]\n",
        "\n",
        "ned1=df_negative[0][:10]\n",
        "ned2=df_negative[1][:10]\n",
        "\n",
        "nud1=df_neutral[0][:10]\n",
        "nud2=df_neutral[1][:10]\n",
        "\n",
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "\n",
        "plt.bar(pd1,pd2, color ='green',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Words in positive dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in positive dataframe-UNIGRAM ANALYSIS\")\n",
        "\n",
        "plt.savefig(\"positive-unigram.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lj55WSyhZk7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_positive.head(10)"
      ],
      "metadata": {
        "id": "C8ZoxK7iZmZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1,figsize=(16,4))\n",
        "\n",
        "plt.bar(ned1,ned2, color ='red',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Words in negative dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in negative dataframe-UNIGRAM ANALYSIS\")\n",
        "\n",
        "plt.savefig(\"negative-unigram.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "psZ-bi_1Zn_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_negative.head(10)"
      ],
      "metadata": {
        "id": "kNtO0mUBZpxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1,figsize=(16,4))\n",
        "\n",
        "plt.bar(nud1,nud2, color ='yellow',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Words in neutral dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in neutral dataframe-UNIGRAM ANALYSIS\")\n",
        "\n",
        "plt.savefig(\"neutral-unigram.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mtk6tAuBZrdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_neutral.head(10)"
      ],
      "metadata": {
        "id": "4pVVKBxSZtHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positiveValues2=defaultdict(int)\n",
        "negativeValues2=defaultdict(int)\n",
        "neutralValues2=defaultdict(int)\n",
        "#get the count of every word in both the columns of df_train and df_test dataframes"
      ],
      "metadata": {
        "id": "tYhtw-tdZvIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the count of every word in both the columns of df_train and df_test dataframes where sentiment=\"positive\"\n",
        "for text in df_train[df_train.sentiment==\"positive\"].news:\n",
        "  for word in generate_N_grams(text,2):\n",
        "    positiveValues2[word]+=1\n",
        "\n",
        "#get the count of every word in both the columns of df_train and df_test dataframes where sentiment=\"negative\"\n",
        "for text in df_train[df_train.sentiment==\"negative\"].news:\n",
        "  for word in generate_N_grams(text,2):\n",
        "    negativeValues2[word]+=1\n",
        "\n",
        "#get the count of every word in both the columns of df_train and df_test dataframes where sentiment=\"neutral\"\n",
        "for text in df_train[df_train.sentiment==\"neutral\"].news:\n",
        "  for word in generate_N_grams(text,2):\n",
        "    neutralValues2[word]+=1"
      ],
      "metadata": {
        "id": "tw5jiHWIZwqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#focus on more frequently occuring words for every sentiment=>\n",
        "#sort in DO wrt 2nd column in each of positiveValues,negativeValues and neutralValues\n",
        "\n",
        "df_positive2=pd.DataFrame(sorted(positiveValues2.items(),key=lambda x:x[1],reverse=True))\n",
        "df_negative2=pd.DataFrame(sorted(negativeValues2.items(),key=lambda x:x[1],reverse=True))\n",
        "df_neutral2=pd.DataFrame(sorted(neutralValues2.items(),key=lambda x:x[1],reverse=True))"
      ],
      "metadata": {
        "id": "L6Ky9diPZ5UQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd1bi=df_positive2[0][:10]\n",
        "pd2bi=df_positive2[1][:10]\n",
        "\n",
        "ned1bi=df_negative2[0][:10]\n",
        "ned2bi=df_negative2[1][:10]\n",
        "\n",
        "nud1bi=df_neutral2[0][:10]\n",
        "nud2bi=df_neutral2[1][:10]\n",
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "\n",
        "plt.bar(pd1bi,pd2bi, color ='green',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Words in positive dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in positive dataframe-BIGRAM ANALYSIS\")\n",
        "\n",
        "plt.savefig(\"positive-bigram.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SfoPAGwjZ64D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_positive2.head(10)"
      ],
      "metadata": {
        "id": "WKJBkVx3Z8UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1,figsize=(16,4))\n",
        "\n",
        "plt.bar(ned1bi,ned2bi, color ='red',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Words in negative dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in negative dataframe-BIGRAM ANALYSIS\")\n",
        "\n",
        "plt.savefig(\"negative-bigram.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cAVEmxcoZ-KZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_negative2.head(10)"
      ],
      "metadata": {
        "id": "H6Y146GGZ_ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1,figsize=(16,4))\n",
        "\n",
        "plt.bar(nud1bi,nud2bi, color ='yellow',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Words in neutral dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in neutral dataframe-BIGRAM ANALYSIS\")\n",
        "\n",
        "plt.savefig(\"neutral-bigram.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h40-zL5eaBMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_neutral2.head(10)"
      ],
      "metadata": {
        "id": "BsCKuFF6aCeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positiveValues3=defaultdict(int)\n",
        "negativeValues3=defaultdict(int)\n",
        "neutralValues3=defaultdict(int)\n",
        "#get the count of every word in both the columns of df_train and df_test dataframes"
      ],
      "metadata": {
        "id": "wbsxBQ1kaEYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the count of every word in both the columns of df_train and df_test dataframes where sentiment=\"positive\"\n",
        "for text in df_train[df_train.sentiment==\"positive\"].news:\n",
        "  for word in generate_N_grams(text,3):\n",
        "    positiveValues3[word]+=1\n",
        "\n",
        "#get the count of every word in both the columns of df_train and df_test dataframes where sentiment=\"negative\"\n",
        "for text in df_train[df_train.sentiment==\"negative\"].news:\n",
        "  for word in generate_N_grams(text,3):\n",
        "    negativeValues3[word]+=1\n",
        "\n",
        "#get the count of every word in both the columns of df_train and df_test dataframes where sentiment=\"neutral\"\n",
        "for text in df_train[df_train.sentiment==\"neutral\"].news:\n",
        "  for word in generate_N_grams(text,3):\n",
        "    neutralValues3[word]+=1"
      ],
      "metadata": {
        "id": "Ep3jsr2caF4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#focus on more frequently occuring words for every sentiment=>\n",
        "#sort in DO wrt 2nd column in each of positiveValues,negativeValues and neutralValues\n",
        "\n",
        "df_positive3=pd.DataFrame(sorted(positiveValues3.items(),key=lambda x:x[1],reverse=True))\n",
        "df_negative3=pd.DataFrame(sorted(negativeValues3.items(),key=lambda x:x[1],reverse=True))\n",
        "df_neutral3=pd.DataFrame(sorted(neutralValues3.items(),key=lambda x:x[1],reverse=True))"
      ],
      "metadata": {
        "id": "fji6rokxah-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd1tri=df_positive3[0][:10]\n",
        "pd2tri=df_positive3[1][:10]\n",
        "\n",
        "ned1tri=df_negative3[0][:10]\n",
        "ned2tri=df_negative3[1][:10]\n",
        "\n",
        "nud1tri=df_neutral3[0][:10]\n",
        "nud2tri=df_neutral3[1][:10]\n",
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "\n",
        "plt.bar(pd1tri,pd2tri, color ='green',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Words in positive dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in positive dataframe-TRIGRAM ANALYSIS\")\n",
        "\n",
        "plt.savefig(\"positive-trigram.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2UWgf3NPajTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_positive3.head(10)"
      ],
      "metadata": {
        "id": "5Ny-ZbeGak29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1,figsize=(16,4))\n",
        "\n",
        "plt.bar(ned1tri,ned2tri, color ='red',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Words in negative dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in negative dataframe-TRIGRAM ANALYSIS\")\n",
        "\n",
        "plt.savefig(\"negative-trigram.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cD9QtvbyamTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_negative3.head(10)"
      ],
      "metadata": {
        "id": "8lcHhzM_aoOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1,figsize=(16,4))\n",
        "\n",
        "plt.bar(nud1tri,nud2tri, color ='yellow',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Words in neutral dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in neutral dataframe-TRIGRAM ANALYSIS\")\n",
        "\n",
        "plt.savefig(\"neutral-trigram.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CwRYTzy1ap7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_neutral3.head(10)"
      ],
      "metadata": {
        "id": "u8oR7OPqarT9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}